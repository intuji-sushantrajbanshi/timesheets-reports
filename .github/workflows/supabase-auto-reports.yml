name: Export Supabase Data to CSV

on:
  schedule:
    - cron: '15 11 * * *' # Every day at 5 PM Nepal/Kathmandu Time (UTC+5:45)
  workflow_dispatch:
  push:
    branches:
      - master
      - main

permissions:
  contents: write
  pages: write
  id-token: write

jobs:
  export-data:
    runs-on: ubuntu-latest
    env:
      SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
      SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
      
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests pandas python-dateutil pytz

      - name: Check Supabase credentials
        run: |
          if [ -z "$SUPABASE_URL" ] || [ -z "$SUPABASE_KEY" ]; then
            echo "‚ùå Supabase credentials are not properly set in GitHub secrets."
            exit 1
          else
            echo "‚úÖ Supabase credentials found"
          fi

      - name: Export data from Supabase
        run: |
          mkdir -p exports
          python -c '
          import os
          import requests
          import pandas as pd
          import json
          from datetime import datetime, timedelta
          
          # Configuration
          supabase_url = os.environ["SUPABASE_URL"]
          supabase_key = os.environ["SUPABASE_KEY"]
          
          # Common headers for all requests
          headers = {
              "apikey": supabase_key,
              "Authorization": f"Bearer {supabase_key}",
              "Content-Type": "application/json",
              "Prefer": "return=representation"
          }
          
          def fetch_data(table_name, query_params=None, select_fields="*"):
              endpoint = f"{supabase_url}/rest/v1/{table_name}"
              
              params = {}
              if select_fields != "*":
                  params["select"] = select_fields
                  
              if query_params:
                  params.update(query_params)
                  
              try:
                  print(f"üîç Fetching from {endpoint} with params {params}")
                  response = requests.get(endpoint, headers=headers, params=params)
                  
                  if response.status_code == 200:
                      data = response.json()
                      if not data:
                          print(f"No data returned for {table_name}")
                          return pd.DataFrame()
                          
                      df = pd.DataFrame(data)
                      print(f"‚úÖ Successfully fetched {len(df)} rows from {table_name}")
                      return df
                  else:
                      print(f"‚ùå Error fetching {table_name}: {response.status_code} - {response.text}")
                      return pd.DataFrame()
                      
              except Exception as e:
                  print(f"‚ùå Error fetching {table_name}: {str(e)}")
                  return pd.DataFrame()
          
          # Calculate date for filtering time entries (last 30 days)
          thirty_days_ago = (datetime.now() - timedelta(days=30)).strftime("%Y-%m-%d")
          current_date = datetime.now().strftime("%Y-%m-%d")
          
          # Table names - adjust these to match your actual Supabase table names
          tables = {
              "companies": "Company",
              "projects": "Project",
              "users": "User",
              "activity_types": "ActivityType",
              "focus_areas": "FocusArea",
              "time_entries": "TimeEntry",
              "submissions": "Submission"
          }
          
          # Export data for each table
          results = {}
          
          # Export active companies
          companies = fetch_data(tables["companies"], {"deletedAt": "is.null"})
          results["companies"] = len(companies) if not companies.empty else 0
          if not companies.empty:
              companies.to_csv("exports/companies.csv", index=False)
              
          # Export active projects
          projects = fetch_data(tables["projects"], {"deletedAt": "is.null"})
          results["projects"] = len(projects) if not projects.empty else 0
          if not projects.empty:
              projects.to_csv("exports/projects.csv", index=False)
              
          # Export active users
          users = fetch_data(tables["users"], {"deletedAt": "is.null"})
          results["users"] = len(users) if not users.empty else 0
          if not users.empty:
              # Remove sensitive fields
              if "password" in users.columns:
                  users = users.drop(columns=["password"])
              users.to_csv("exports/users.csv", index=False)
              
          # Export activity types
          activity_types = fetch_data(tables["activity_types"], {"deletedAt": "is.null"})
          results["activity_types"] = len(activity_types) if not activity_types.empty else 0
          if not activity_types.empty:
              activity_types.to_csv("exports/activity_types.csv", index=False)
              
          # Export focus areas
          focus_areas = fetch_data(tables["focus_areas"], {"deletedAt": "is.null"})
          results["focus_areas"] = len(focus_areas) if not focus_areas.empty else 0
          if not focus_areas.empty:
              focus_areas.to_csv("exports/focus_areas.csv", index=False)
              
          # Export time entries from last 30 days
          time_entries = fetch_data(tables["time_entries"], 
                                  {"deletedAt": "is.null", 
                                   "entryDate": f"gte.{thirty_days_ago}"})
          results["time_entries"] = len(time_entries) if not time_entries.empty else 0
          if not time_entries.empty:
              time_entries.to_csv("exports/time_entries.csv", index=False)
              
          # Export submissions
          submissions = fetch_data(tables["submissions"], {"deletedAt": "is.null"})
          results["submissions"] = len(submissions) if not submissions.empty else 0
          if not submissions.empty:
              submissions.to_csv("exports/submissions.csv", index=False)
              
          # Create a summary file with export information
          with open("exports/export_summary.json", "w") as f:
              summary = {
                  "export_date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                  "tables_exported": results,
                  "time_entries_period": f"{thirty_days_ago} to {current_date}"
              }
              json.dump(summary, f, indent=2)
          
          # Get current timestamp for HTML
          timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
          
          # Create an index.html file for GitHub Pages
          html_content = f"""<!DOCTYPE html>
          <html>
          <head>
              <title>Supabase Data Exports</title>
              <meta charset="UTF-8">
              <meta name="viewport" content="width=device-width, initial-scale=1">
              <style>
                  body {{ font-family: Arial, sans-serif; margin: 0; padding: 20px; line-height: 1.6; }}
                  h1 {{ color: #333; }}
                  .container {{ max-width: 800px; margin: 0 auto; }}
                  table {{ width: 100%; border-collapse: collapse; margin: 20px 0; }}
                  th, td {{ padding: 12px; text-align: left; border-bottom: 1px solid #ddd; }}
                  th {{ background-color: #f2f2f2; }}
                  .download-btn {{ display: inline-block; background-color: #4CAF50; color: white; 
                                  padding: 8px 16px; text-decoration: none; border-radius: 4px; }}
                  .download-btn:hover {{ background-color: #45a049; }}
                  .timestamp {{ color: #666; font-style: italic; }}
              </style>
          </head>
          <body>
              <div class="container">
                  <h1>Supabase Data Exports</h1>
                  <p class="timestamp">Last updated: {timestamp} UTC</p>
                  
                  <table>
                      <tr>
                          <th>Dataset</th>
                          <th>Records</th>
                          <th>Download</th>
                      </tr>"""
          
          # Add table rows dynamically
          for table_name, count in results.items():
              file_name = f"{table_name}.csv"
              display_name = table_name.replace("_", " ").title()
              
              if table_name == "time_entries":
                  display_name += " (Last 30 Days)"
                  
              download_link = f"""
                      <tr>
                          <td>{display_name}</td>
                          <td>{count}</td>
                          <td>"""
              
              if count > 0:
                  download_link += f"""<a href="{file_name}" class="download-btn">Download CSV</a>"""
              else:
                  download_link += """<span style="color: #999;">No data</span>"""
                  
              download_link += """</td>
                      </tr>"""
              
              html_content += download_link
          
          # Complete the HTML
          html_content += f"""
                  </table>
                  
                  <h2>Export Summary</h2>
                  <p>Time period for time entries: {thirty_days_ago} to {current_date}</p>
                  <p><a href="export_summary.json">View detailed export summary (JSON)</a></p>
              </div>
          </body>
          </html>"""
          
          with open("exports/index.html", "w") as f:
              f.write(html_content)
          
          # Check if we have any successful exports
          successful_exports = sum(1 for count in results.values() if count > 0)
          if successful_exports == 0:
              print("‚ö†Ô∏è Warning: No data was successfully exported from any table")
              print("Please check your Supabase configuration and table access permissions")
              
              # Create a placeholder file
              with open("exports/README.md", "w") as f:
                  f.write(f"""# Supabase Export Attempt
          
          No data could be exported on {timestamp}.
          
          Possible reasons:
          1. Table names might be different
          2. API key permissions
          3. Row Level Security (RLS) policies
          4. Tables in non-public schema
          
          Please check your Supabase configuration.
          """)
          else:
              print(f"‚úÖ Successfully exported data from {successful_exports} tables")
          '

      - name: Check for exported files
        run: |
          echo "üìÅ Contents of exports directory:"
          ls -la exports/ || echo "No exports directory found"
          
          if [ -d "exports" ] && [ "$(ls -A exports)" ]; then
            echo "‚úÖ Export files found"
          else
            echo "‚ö†Ô∏è No export files found, creating placeholder"
            mkdir -p exports
            echo "No data available" > exports/no-data.txt
          fi

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: supabase-exports
          path: exports/
          retention-days: 30

      - name: Setup Pages
        uses: actions/configure-pages@v4
        if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'

      - name: Upload to GitHub Pages
        uses: actions/upload-pages-artifact@v3
        if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'
        with:
          path: './exports'

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
        if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'

      - name: Commit and push changes
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add exports/
          git diff --staged --quiet || git commit -m "Update exported data - $(date)"
          git push
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
